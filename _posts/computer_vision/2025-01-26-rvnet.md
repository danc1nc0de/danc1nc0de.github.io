---
title: 快速了解一个网络：RVNet, Deep Sensor Fusion of Monocular Camera and Radar for Image-Based Obstacle Detection in Challenging  Environments
date: 2025-01-26 11:00:00 +0800
categories: [Computer Vision]
tags: [快速了解一个网络, computer vision, 2d detection, radar-camera fusion]
---

> 以下内容偏向于记录个人学习过程及思考，请审慎阅读。
{: .prompt-info }

## 背景

基于camera的目标检测算法在低照明度、雨雪天气容易表现不佳

radar可以很好的应对这类场景，但radar的点云又比较稀疏，很难勾勒出目标的几何信息。

## 核心思想

提出一种radar camera融合的方案。

将radar点云通过radar to camera外参 + camera内参投影到camera图像上，建立sparse radar image，每个点包含radar的深度和横纵向速度信息。

分别对camera image和sparse radar image通过cnn的方式提取feature，再通过concatenation的方式融合，进而再进一步通过cnn的方式提取融合后的feature。

## Pipeline

![rvnet-pipeline](assets/img/rvnet-pipeline.png)

## 亿些细节

- 作者基于nuScenes数据集进行实验
- image feature提取的部份采用了yolov3-tiny的结构，并使用了基于Pascal VOC数据集的pretrained权重。
- 因为radar image比较稀疏，作者使用了stride为1的卷积核，把所有radar feature都考虑上
- radar feature是基于随机权重开始训练的。
- 作者也提到一种dense的radar image方式。
  - 作者将固定169个radar点云排成13x13的矩阵，每个点代表一个点云，其包含深度、横纵向速度、反投图像上的uv共五个量（类似于稀疏矩阵的表达方式）
- 作者提到几种输出的变种
  - 包括大小障碍物的输出主要靠融合结果还是camera结果
  - 输出障碍物类别是二分类还是多分类等
- 作者发现radar-camera融合的二分类效果提升比较明显

## 进一步了解

- yolov3-tiny

## 原文和代码

本文作为一篇会议论文收录在一本书里，可以考虑通过libgen下载

- Image and Video Technology (PSIVT 2019), pp. 351-364

## 参考资料

无