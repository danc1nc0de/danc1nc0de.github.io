---
title: 快速了解一个网络：MAE, Masked Autoencoders Are Scalable Vision Learners
date: 2025-05-19 09:30:00 +0800
categories: [Computer Vision]
tags: [快速了解一个网络, computer vision, self-supervised]
---

> 以下内容偏向于记录个人学习过程及思考，请审慎阅读。
{: .prompt-info }

## 背景

得益于硬件的发展，当前网络可以很容易在有标签的图像上进行大规模训练。而labeled images通常是难以获取的。

在自然语言处理（NLP）中，这一问题被有效解决，如GPT中的autoregressive language modeling及BERT中的masked autoencoding：

*将一段话中的部分数据进行移除，并使用网络预测移除的部分。*

作者考虑在images中做同样的事情，预训练一个视觉大模型以用于迁移至其它视觉任务。

## 核心思想

将输入图像随机移除部分patch，并用网络预测并重建移除的部分。

## Pipeline

![mae-pipeline](assets/img/mae-pipeline.png)

基于VIT架构，将输入图像的patch随机去除部分，将剩余部分送入encoder进行编码；

对于decoder部分，将encoder的输出+之前移除的patch对应的mask tokens（可学习）共同送入；

最终输出结果与完整图像求MSE作为loss进行反向传播。

## 亿些细节

- 在视觉中，decoder的目的是恢复重建移除部分的图像像素，因此相比于NLP中的任务是of a lower sematic level的，因此作者设计了非对称的encoder/decoder架构，decoder相对更轻量。
- 作者认为，移除绝大部分patch用于MAE训练可以达到“双赢”的情况：encoders的输入patch变少了，计算量减小；可以增强网络的准确度和理解力
- 作者尝试了多种随机去除patch的方法，最后发现基于平均分布的随机采样去除是最合理有效的（避免了bias，如图像中心部分移除了更多的patch）
- MAE encoder部分的输入，只有未被移除的patch，不含已经移除的patch对应的mask tokens
- MAE decoder部分的输入，包含encoder编码的未被移除的patch以及已经移除patch对应的mask tokens
- MAE decoder只在预训练过程中使用，实际后续用作迁移其它视觉任务是使用encoder部分（重点利用encoder部分的图像理解和编码能力）
- 在Reconstruction target过程中，decoder最后跟了一个线性映射层将图像解码
 
self.decoder_pred = nn.Linear(decoder_embed_dim, patch_size**2 * in_chans, bias=True) # decoder to patch

- loss为MSE，且只计算被去除部分的patch（结果导向，因为作者做了实验，用全部patch求loss会掉点0.5%）
- 实验表明移除75%的patch，在各种迁移任务上是最优的。
- **The fine-tuning accuracy heavily depends on pre-training.**
- cropping-only的augmentation在MAE中效果良好

## 进一步了解

- [BERT](https://arxiv.org/abs/1810.04805)

## 原文和代码

<https://arxiv.org/abs/2111.06377>

<https://github.com/facebookresearch/mae>

## 参考资料

无