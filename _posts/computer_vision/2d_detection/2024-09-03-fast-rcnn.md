---
title: 每天学网络：Fast RCNN
date: 2024-09-03 09:00:00 +0800
categories: [Computer Vision, 2D Detection]
tags: [每天学网络, computer vision, 2d detection, fast rcnn]
---

> 以下内容偏向于记录个人学习过程及思考，非常规教学内容
{: .prompt-info }

## 背景

RCNN不管是训练还是推理都太慢了。

- 训练是多阶段的，需要先训CNN提特征，再训SVM分类，bbox还要再训回归网络。
- 由于要存储所有CNN提取的feature，需要大量存储资源
- 推理过程很久，RCNN需要对所有的约2000个region proposals走一遍CNN

后来提出的[SPP-net](https://yinghao.info/posts/spp-net)解决了以上上面的最后1个问题

- 将原始图像的region proposals按照CNN结构映射到feature maps上，只用CNN对原始输入图像推理一遍，后续直接在提取的feature maps上做分类或检测

但是[SPP-net](https://yinghao.info/posts/spp-net)还是没有解决上述前2个问题

## 核心思想

**end to end，做成一阶段训练，不需要额外存储feature**

## Pipeline

![fast-rcnn-pipeline](assets/img/fast-rcnn-pipeline.png)

1. 对于整幅输入图像使用CNN提取feature，得到feature map
2. 将region proposals映射/投影到feature map，抠出该区域feature
3. 对于该区域做一次ROI pooling，处理不同大小的proposals（其实就是[SPP-net](https://yinghao.info/posts/spp-net)中的一次空间金字塔池化层）
4. 末尾接入2个并行的全连接层，分别做分类和bbox回归，多任务loss

## 亿些细节

### 使用预训练网络

使用基于ImageNet训练的分类网络，将固定大小的最大池化层替换为ROI池化层，将最后的全连接层和softmax替换为两个并行的全连接层，分别加上softmax分类和bbox回归

并且，需要将输入变为2个，即图像 + region proposals

### 微调过程

选择少图像 + 多proposals形式的mini batch方式训练，可以减少资源消耗，提升训练速度

### 多任务loss

分类损失 + 非背景类的bbox回归损失（使用smooth L1 loss）

### 检测加速

检测任务需要多个proposals进入全连接层进行计算，成为了耗时瓶颈。

因此，本文采用多全连接层的加速方法：基于奇异值分解截断的方法

## 进一步了解

smooth L1 loss（TODO）

奇异值分解（SVD）（TODO）

## 原文和代码

<https://arxiv.org/abs/1504.08083>

## 参考资料

{% include embed/bilibili.html id='BV1y94y1Q7QJ' %}