---
title: 快速了解一个网络：AssociationNet, Radar Camera Fusion via Representation Learning in Autonomous Driving
date: 2025-02-02 21:30:00 +0800
categories: [Computer Vision]
tags: [快速了解一个网络, computer vision, radar-camera fusion, representation learning, association net]
math: true
---

> 以下内容偏向于记录个人学习过程及思考，请审慎阅读。
{: .prompt-info }

## 背景

本文旨在通过representation learning解决radar点和camera image 2d检测框的关联问题。 

## 核心思想

使用基于规则的关联算法输出结果作为真值进行监督。

将image 2d box、radar点和原始RGB图像concat到一起，经过encode、decode结构得到feature map

将feature map分成radar和camera两部分，分别从radar点位置和2d box中心位置取对应pixel处的64个channel值作为representation vector，欧式距离比较小的两个向量则认为关联。

## Pipeline

![assoc-net-pipeline](assets/img/assoc-net-pipeline.png)

![assoc-net-architecture](assets/img/assoc-net-architecture.png)

## 亿些细节

### Radar and Camera Data Preprocessing

对于每一个camera帧，找离它最近的radar帧，并通过radar速度+匀速假设补偿一下radar位置

出2d box的网络采用RetinaNet

### Deep Association by Representation Learning

将radar点和2d box都投到image plane得到pseudo-image，每个attribute占据一个channel

radar部份channels包含id, obstacle prob, pos_x, pos_y, vel_x, vel_y以及一个heatmap表示反投到图像上的位置。

2d box部份channels包含2d box的width, height, class以及一个heatmap表示2d box中心点的位置。

以ResNet-50为backbone，跟一个FPN用来decoding feature map，再增加额外的两层将feature map恢复成原始图像大小

输出部份为128个channel，对应radar pin和2d box的两个64维的representation vector

loss方面，用规则生成的关联关系来监督，包括pull loss和push loss，其中

- pull loss: 关联的2d box和radar点，让其representation vector的欧式距离尽可能接近一个较小的预设的阈值（本文为2.0）
- push loss: 非关联的2d box和radar点，让其representation vector的欧式距离尽可能接近一个较大的预设的阈值（本文为8.0）

### Loss Sampling

因为push loss中对应的非关联的2d box和radar点数量非常巨大，因此这里随机采样一些点对来作为push loss

作者实验发现采样点对数量与pull loss中的点对数量一致时效果最好

### Ordinal Loss

对于相近距离的目标，有时候近距离的radar反而会关联到较远距离的box上，因此需要引入一个ordinal loss来惩罚这种错误

作者利用了2d box底边的y坐标和radar的深度来作额外监督

2d box底边y坐标越小时，深度应当越近，因此(yi - yj)(di - dj)应当是正号，可以利用这个来增加loss，详见原文公式。

### Inference

每个2d box可能关联多个radar point

但每个radar point一定关联固定的一个2d box

因此本文对每个radar point选择其对应欧式距离最小的2d box，详见Figure 4

## 进一步了解

- RetinaNet
- FPN

## 原文和代码

<https://arxiv.org/abs/2103.07825>

## 参考资料

无